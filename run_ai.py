# ================= å¼ºåŠ›å…¼å®¹è¡¥ä¸ =================
import sys
import os

try:
    import pyparsing

    if not hasattr(pyparsing, 'DelimitedList'):
        if hasattr(pyparsing, 'delimited_list'):
            pyparsing.DelimitedList = pyparsing.delimited_list
        elif hasattr(pyparsing, 'delimitedList'):
            pyparsing.DelimitedList = pyparsing.delimitedList
except ImportError:
    pass
# ===============================================

import time
import google.generativeai as genai

# ğŸ”´ğŸ”´ğŸ”´ å¡«å…¥ä½ çš„ API KEY ğŸ”´ğŸ”´ğŸ”´
API_KEY = ""

# ğŸŒ ä»£ç†è®¾ç½® (å¦‚æœéœ€è¦)
# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'
# os.environ['HTTP_PROXY']  = 'http://127.0.0.1:7890'

# è·¯å¾„è®¾ç½®
DESKTOP = os.path.join(os.path.expanduser("~"), "Desktop")
# DESKTOP = r"C:\Users\lnykk\Desktop" # æ‰‹åŠ¨æŒ‡å®šå¤‡ç”¨

FILE_LOG = os.path.join(DESKTOP, "Sims4_Story_Log_Full.txt")
FILE_PROFILE = os.path.join(DESKTOP, "Character_Profile.txt")
FILE_INBOX = os.path.join(DESKTOP, "Sims4_Inbox.txt")
FILE_MEMORY = os.path.join(DESKTOP, "Story_Memory.txt")
FILE_ARCHIVE = os.path.join(DESKTOP, "Story_Archive.txt")

genai.configure(api_key=API_KEY)


def ask_gemini(new_log, profile, memory):
    print("âœ¨ AI æ­£åœ¨æ„æ€å‰§æƒ…...")
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªã€Šæ¨¡æ‹Ÿäººç”Ÿ4ã€‹çš„å‰§æƒ…å¯¼æ¼”ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€æ®µç®€çŸ­çš„å‰§æƒ…æ›´æ–°ã€‚

    ã€è§’è‰²äººè®¾ã€‘
    {profile}

    ã€å‰æƒ…æè¦ã€‘
    {memory}

    ã€åˆšåˆšå‘ç”Ÿçš„äº‹ä»¶ã€‘
    {new_log}

    ã€ä»»åŠ¡è¦æ±‚ã€‘
    1. ä½ æ˜¯ä¸€ä½ç¬”è§¦ç»†è…»ã€é£æ ¼å¹½é»˜çš„ç°ä»£å°è¯´å®¶ï¼Œç»“åˆäººè®¾å’Œäº‹ä»¶ï¼Œå†™ä¸€æ®µ **800å­—ä»¥å†…** çš„å‰§æƒ…æ—ç™½ï¼Œå†…å®¹ä¸ºç®€ä½“å­—ï¼Œä¸è¦ä½¿ç”¨ç¹ä½“å­—ã€‚é£æ ¼ç”ŸåŠ¨å…·æœ‰æˆå‰§æ€§ï¼Œäººç‰©é²œæ´»ï¼Œå†…å®¹å…·æœ‰é«˜å¯è¯»æ€§ï¼Œå°½é‡ä¸è¦å†™å®šäºè¿‡äºé•¿çš„å¥å­ï¼Œæ‹’ç»ç¿»è¯‘è…”ï¼Œå‰§æƒ…å†…å®¹ä¸­ä¸è¦å¸¦æœ‰logä¸­çš„æ‚ä¹±çš„æ•°æ®ï¼Œè¯·æŠŠæ¸¸æˆæœ¯è¯­éšå½¢åŒ–ã€‚ä¸è¦æ¯æ¬¡éƒ½æåˆ°è§’è‰²çš„ç‰¹è´¨ï¼åªæœ‰å½“ç‰¹è´¨å¯¼è‡´äº†**åå¸¸**æˆ–**æå…¶å…¸å‹**çš„è¡Œä¸ºæ—¶æ‰é¡ºå¸¦ä¸€æã€‚å‰§æƒ…è¦æœ‰è½»é‡ç¼“æ€¥ï¼Œä¸è¦æŠŠæ‰€æœ‰çç¢çš„å–æ°´ã€ä¸Šå•æ‰€éƒ½å†™å¾—åƒå²è¯—ä¸€æ ·å®å¤§ã€‚é‡ç‚¹æå†™å†²çªã€‚å½“æƒ…æ™¯åˆé€‚æ—¶ï¼Œå¯é€‚å½“æå†™äººç‰©è¯´äº†ä»€ä¹ˆï¼Œè¯´äº†å“ªäº›è¯ï¼Œåƒæ˜¯è¿™ä¸ªäººç‰©åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ä¼šè¯´çš„è¯ã€‚
    2. ç”Ÿæˆä¸€ä¸ªæ–°çš„â€œå‰æƒ…æè¦â€ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
    å‰§æƒ…å†…å®¹...
    ||SPLIT||
    æ–°çš„å‰æƒ…æè¦...
    """

    try:
        # â¬‡ï¸ æ¢æˆä½ çš„åˆ—è¡¨é‡Œæœ‰çš„ 'gemini-flash-latest'
        # è¿™æ˜¯ä¸€ä¸ªåˆ«åï¼Œé€šå¸¸æŒ‡å‘å½“å‰ç¨³å®šçš„ Flash ç‰ˆæœ¬
        model = genai.GenerativeModel('gemini-flash-latest')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        error_str = str(e)
        if "429" in error_str:
            print(f"âš ï¸ è§¦å‘é¢‘ç‡é™åˆ¶ (429)ï¼")
            print("â˜• AI éœ€è¦ä¼‘æ¯ä¸€ä¸‹ï¼Œè„šæœ¬å°†è‡ªåŠ¨æš‚åœ 60 ç§’...")
            time.sleep(60)
            return None
        elif "404" in error_str:
            print(f"âŒ æ¨¡å‹ 404ï¼šå¯èƒ½æ˜¯ç½‘ç»œæ²¡èµ°ä»£ç†ï¼Œæˆ–è€…æ¨¡å‹åå­— {model.model_name} ä¸å¯ç”¨ã€‚")
        else:
            print(f"âŒ API è¿æ¥å¤±è´¥: {e}")
        return None


def main():
    print("ğŸš€ AI åŠ©æ‰‹å¯åŠ¨ (é€‚é…ç‰ˆ V24.0)ï¼")
    print(f"ğŸ“‚ æ­£åœ¨ç›‘æ§: {FILE_LOG}")

    # åˆå§‹åŒ–æ–‡ä»¶
    for f in [FILE_PROFILE, FILE_MEMORY, FILE_ARCHIVE]:
        if not os.path.exists(f):
            with open(f, "w", encoding="utf-8") as file: file.write("")

    last_size = 0
    if os.path.exists(FILE_LOG):
        last_size = os.path.getsize(FILE_LOG)
        print(f"â„¹ï¸ å½“å‰æ—¥å¿—å¤§å°: {last_size}")

    while True:
        try:
            time.sleep(5)

            if not os.path.exists(FILE_LOG): continue

            current_size = os.path.getsize(FILE_LOG)

            if current_size < last_size:
                last_size = current_size
                continue

            if current_size > last_size:
                print(f"ğŸ“¨ æ”¶åˆ°æ–°æ—¥å¿—ï¼({current_size - last_size} å­—èŠ‚)")

                try:
                    with open(FILE_LOG, "r", encoding="utf-8") as f:
                        f.seek(last_size)
                        new_content = f.read().strip()
                except:
                    continue

                last_size = current_size

                if not new_content: continue

                # è¯»å–ä¸Šä¸‹æ–‡
                profile = ""
                memory = ""
                if os.path.exists(FILE_PROFILE):
                    with open(FILE_PROFILE, "r", encoding="utf-8") as f: profile = f.read()
                if os.path.exists(FILE_MEMORY):
                    with open(FILE_MEMORY, "r", encoding="utf-8") as f: memory = f.read()

                # å‘¼å« AI
                result = ask_gemini(new_content, profile, memory)

                if result and "||SPLIT||" in result:
                    parts = result.split("||SPLIT||")
                    story = parts[0].strip()
                    new_mem = parts[1].strip() if len(parts) > 1 else memory

                    with open(FILE_INBOX, "w", encoding="utf-8") as f:
                        f.write(story)
                    print(f"âœ… å‰§æƒ…å·²å‘é€ç»™æ¸¸æˆï¼")

                    with open(FILE_MEMORY, "w", encoding="utf-8") as f:
                        f.write(new_mem)

                    with open(FILE_ARCHIVE, "a", encoding="utf-8") as f:
                        f.write(f"\n{story}\n")
                else:
                    if result: print(f"âš ï¸ æ ¼å¼å¼‚å¸¸ï¼Œè·³è¿‡æœ¬æ¬¡")

        except KeyboardInterrupt:
            print("\nğŸ›‘ ç¨‹åºå·²åœæ­¢")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
            time.sleep(5)


if __name__ == "__main__":

    main()
